{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>\n",
    "    ECE 438 - Laboratory 9a<br/>\n",
    "    Speech Processing (Week 1)<br/>\n",
    "    <small>Last Updated on March 29, 2022</small><br/>\n",
    "    <br/>\n",
    "    Date:<br/>\n",
    "    Section:<br/>\n",
    "</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Name |Signature |Time spent outside lab|\n",
    "|:---:|:---:|:---:|\n",
    "|Student Name #1 [---%]| | |\n",
    "|Student Name #2 [---%]| | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||Below expectations| Lacks in some respect|Meets all expectations|\n",
    "|:---:|:---:|:---:|:---:|\n",
    "|**Completeness of the report**||||\n",
    "|**Organization of the report**||||\n",
    "|**Quality of figures**: *Correctly labeled with title, x-axis, y-axis, and name(s)*||||\n",
    "|**Understanding differences between voiced/unvoiced segments(30 pts)**: *Python plots and code(zero cross), questions*||||\n",
    "|**Understanding and implementation of short-time DTFT (30 pts)**: *Python plots and code(DFTwin), questions*||||\n",
    "|**Understanding and implementation of spectrogram (40 pts)**: *Python plots and code(specgm), questions, formant estimates*||||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import IPython.display as ipd\n",
    "from helper import hamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the size of the plot\n",
    "plt.rcParams['figure.figsize'] = (16, 6)\n",
    "\n",
    "# make sure the plot is displayed in this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red;\"><left>Exercise 2.2: Classification of Voiced/Unvoiced Speech</left></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Load the audio `Start.wav` using `start, fs = sf.read(\"Start.wav\")`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Plot (not stem) the speech signal. Then identify two segments of the signal: one segment that is voiced and a second segment that is unvoiced. To identify them, you can choose one from the following options:**\n",
    "  * a. Circle the regions of the plot of the speech signal corresponding to these two segments.\n",
    "  * b. Plot the regions corresponding to these two segments separately in new cells.\n",
    "  * c. Print the starting and ending indices of these two regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporarily make the plot interactive\n",
    "%matplotlib notebook\n",
    "# specify the size of the plot\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the plot not interactive\n",
    "%matplotlib inline\n",
    "# specify the size of the plot\n",
    "plt.rcParams['figure.figsize'] = (16, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Extract $300$ samples from the voiced segment of the speech into a NumPy vector called ```VoicedSig```. Also, extract $300$ samples from the unvoiced segment of the speech into a NumPy vector called ```UnvoicedSig```.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Plot the two signals, ```VoicedSig``` and ```UnvoicedSig```.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Explain how you selected your voiced and unvoiced regions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Estimate the pitch period for the voiced segment. Keep in mind that these speech signals are sampled at $8$ KHz, which means that the time between samples is $0.125$ milliseconds (ms). Typical values for the pitch period are $8$ ms for male speakers, and $4$ ms for female speakers. Based on this, would you predict that the speaker is male, or female?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Complete the function below that calculates equation (1) to compute the average energy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_energy(x):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ---\n",
    "    x: the input signal\n",
    "    \n",
    "    Returns\n",
    "    ---\n",
    "    P: the average energy of the signal\n",
    "    \"\"\"\n",
    "    P = None\n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Use this function to compute the average energy of the voiced and unvoiced segments that you plotted above. Print the values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. For which segment is the average energy greater?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Complete the function below to compute the number of zero-crossings that occur within a vector.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zero_cross(x):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ---\n",
    "    x: the input signal\n",
    "    \n",
    "    Returns\n",
    "    ---\n",
    "    cnt: the number of zero-crossings\n",
    "    \"\"\"\n",
    "    \n",
    "    cnt = 0\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Compute and print the numbers of zero-crossings of both ```VoicedSig``` and ```UnvoicedSig```.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11. Which segment has more zero-crossings?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red;\"><left>Exercise 3.2</left></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Complete the function below to compute the DFT of a windowed length $L$ segment of the vector $x$.**\n",
    "\n",
    "**Note:**\n",
    "* You should use a Hamming window of length $L$ to window $x$\n",
    "* Your window should start at the index $m$ of the signal $x$.\n",
    "* Your DFTs should be of length $N$\n",
    "* You may use ```hamming(L)``` function to obtain the Hamming window.\n",
    "* You may use ```np.fft.fft()``` function to compute the DFTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFTwin(x, L, m, N):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ---\n",
    "    x: the input signal\n",
    "    L: the length of the Hamming window\n",
    "    m: the starting index of the signal x where the Hamming window is applied\n",
    "    N: the length of DFT\n",
    "    \n",
    "    Returns\n",
    "    ---\n",
    "    X: the DFT of a windowed length L segment of x\n",
    "    \"\"\"\n",
    "    \n",
    "    X = None\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Load the file ```go.au```.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Plot the signal and locate a voiced region, which should cover six pitch periods.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporarily make the plot interactive\n",
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "# specify the size of the plot\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the plot not interactive\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# specify the size of the plot\n",
    "plt.rcParams['figure.figsize'] = (16, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Plot the voiced region.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Use ```DFTwin()``` to compute a $512$-point DFT of the speech segment, with a window that covers $6$ pitch periods within the voiced region, and then plot it for $0\\leq \\omega\\leq\\pi$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Describe the general shape of the spectrum, and estimate the formant frequencies for the region of voiced speech.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red;\"><left>Exercise 3.4</left></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Complete the function below that can create a spectrogram using your ```DFTwin()``` function from the previous section. You will do this by creating a matrix of windowed DFTs, oriented as described above.**\n",
    "\n",
    "**Important hints:**\n",
    "<!-- * Remember that frequency in a spectrogram increases along the positive y-axis, which means that the first few elements of each column of the matrix will correspond to the highest frequencies -->\n",
    "* You can start by initializing `A` as an empty list, then keep appending the DFT results from `DFTwin()` to it. At the end, convert it to a NumPy array by `A = np.array(A)`.\n",
    "* After you do the step above, you should find that the frequency components are on the x-axis, but we want them to be on the y-axis. You might use `np.transpose()`.\n",
    "* Your ```DFTwin()``` function returns the DT spectrum for frequencies between $0$ and $2\\pi$. Therefore, you will only need to use the first or second half of these DFTs.\n",
    "* The statement ```B[:, n]``` references the entire $n$th (zero-based index) column of the matrix ```B```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Specgm(x, L, overlap, N):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ---\n",
    "    x: the input signal\n",
    "    L: the window length\n",
    "    overlap: the number of points common to successive windows\n",
    "    N: the number of points computed in each DFT\n",
    "    \n",
    "    Returns\n",
    "    ---\n",
    "    A: the matrix of spectrogram\n",
    "    \"\"\"\n",
    "    \n",
    "    A = None\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Load the file ```signal.npy``` using ```np.load()```. Plot the signal.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Plot the magnitude (in dB) of the wideband spectrogram, using a window length of $50$ samples and an overlap of $30$ samples.**\n",
    "\n",
    "* In labeling the axes of the image, assume a sampling frequency of $8$ KHz. Then the frequency will range from $0$ to $4000$ Hz.\n",
    "* Set the parameter `extent=[0, len(signal) / 8000, 1, 4001]` in `plt.imshow()` to correctly label the axes.\n",
    "* Set the parameter `aspect='auto'` in `plt.imshow()`.\n",
    "* You can get a pseudo-color mapping by setting the parameter ```cmap='jet'``` in ```plt.imshow()```. \n",
    "* Set the parameter ```origin='lower'``` or ```origin='upper'``` in ```plt.imshow()``` to place the origin of your plot in the lower/upper left corner, depending on your matrix returned by `Specgm()`.\n",
    "* For more information, see the online help for the [```plt.imshow()```](https://matplotlib.org/3.1.0/api/_as_gen/matplotlib.axes.Axes.imshow.html) command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Plot the magnitude (in dB) of the narrowband spectrogram, using a window length of $320$ samples and an overlap of $60$ samples.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Do you see vertical striations in the wideband spectrogram? Similarly, do you see horizontal striations in the narrowband spectrogram? In each case, what causes these lines, and what does the spacing between them represent?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red;\"><left>Exercise 3.6</left></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Run the following code to load the vowel utterances *a*, *e*, *i*, *o*, and *u* from a female speaker.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(\"a.npy\")\n",
    "e = np.load(\"e.npy\")\n",
    "i = np.load(\"i.npy\")\n",
    "o = np.load(\"o.npy\")\n",
    "u = np.load(\"u.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Plot the magnitude (in dB) of the narrowband spectrogram of each of the utterances.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. For the vowels a and u, estimate the first two formant frequencies using the functions you created in the previous sections. Make your estimates at a time frame toward the beginning of the utterance, and another set of estimates toward the end of the utterance. You may want to use both the `Specgm()` and `DFTwin()` functions to determine the formants. Plot these four points in the vowel triangle provided in the file `vowel_triangle.pdf`. For each vowel, draw a line connecting the two points, and draw an arrow indicating the direction the formants are changing as the vowel is being uttered.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remember to append `vowel_triangle.pdf` when you submit the report on Gradescope."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
